import os
import asyncio
import random
import time
from datetime import datetime
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
from core import config_parser
from utils.files import save_to_jsonl
from utils.normalize import extract_cian_id
from utils.browser import block_heavy_resources, click_next_page
from core.logger import setup_logger
from utils.s3_client import upload_file_to_s3

logger = setup_logger()


async def collect_flats_from_url(browser, flat_ids: set, url: str, filename):
    context = await browser.new_context(
        user_agent=random.choice(config_parser.USER_AGENTS),
        extra_http_headers=config_parser.DEFAULT_HEADERS
    )
    page = await context.new_page()
    await block_heavy_resources(page)

    await page.goto(url, wait_until="domcontentloaded", timeout=20000)
    if await page.locator(config_parser.CAPCHA_BLOCK_TEXT).count() > 0:
        logger.error(f"‚ùå –ë–õ–û–ö–ò–†–û–í–ö–ê –ò–õ–ò –ö–ê–ü–ß–ê: {url}")
        raise Exception(f"–ö–∞–ø—á–∞ –Ω–∞ {url}")
        
    for page_num in range(config_parser.MAX_PAGES_TO_PARSE):
        content = await page.content()
        soup = BeautifulSoup(content, 'html.parser')
        
        cards = soup.find_all("article", {"data-name": "CardComponent"}) 

        logger.info(f"üîé –ö–≤–∞—Ä—Ç–∏—Ä —Å–ø–∞—Ä—Å–µ–Ω–æ - {len(flat_ids)}. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num + 1}. URL: {url}")
        for card in cards:
            try:
                link_el = card.find("a", href=True)
                if not link_el: continue
                link = link_el['href']
                cian_id = extract_cian_id(link)

                if cian_id in flat_ids: continue
                
                price_el = card.find("span", {"data-mark": "MainPrice"})
                price_text = price_el.get_text() if price_el else None

                title_el = card.find("span", {"data-mark": "OfferSubtitle"}) or \
                            card.find("span", {"data-mark": "OfferTitle"})
                title = title_el.get_text() if title_el else None

                geo_labels = card.find_all("a", {"data-name": "GeoLabel"})
                all_geo_texts = [g.get_text() for g in geo_labels]
                address = ", ".join(all_geo_texts)

                metro_container = card.find("div", {"data-name": "SpecialGeo"})
                metro = None
                if metro_container:
                    metro = metro_container.get_text()

                desc_el = card.find('div', {'data-name': 'Description'})
                description = desc_el.get_text(strip=True) if desc_el else None

                flat_data = {
                    "id": cian_id,
                    "link": link,
                    "title": title,
                    "price": price_text,
                    "address": address,
                    "metro": metro,
                    "parsed_at": datetime.now().isoformat(),
                    "description": description
                }

                await save_to_jsonl(flat_data, filename)
                flat_ids.add(cian_id)

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ URL: {url}. –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {page_num + 1}. {e}")
                continue

        if page_num + 1 < config_parser.MAX_PAGES_TO_PARSE:
            success = await click_next_page(page, "nav[data-name='Pagination'] a")
            if not success:
                logger.warning(f"‚ö†Ô∏è  –ù–µ –Ω–∞—à–µ–ª –∫–Ω–æ–ø–∫—É '–î–∞–ª—å—à–µ' –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num + 1}")
                break

    logger.info(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω —Å–±–æ—Ä —Å URL: {url}")
    await context.close()


async def main():
    os.makedirs("data", exist_ok=True)

    env_date = os.getenv("EXECUTION_DATE")
    if env_date:
        start_time_dt = datetime.strptime(env_date, "%Y-%m-%d")
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É—é –¥–∞—Ç—É –∏–∑ Airflow: {env_date}")
    else:
        start_time_dt = datetime.now()
        logger.info(f"–î–∞—Ç–∞ –∏–∑ Airflow –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—é —Ç–µ–∫—É—â—É—é: {start_time_dt.strftime('%Y-%m-%d')}")

    async with async_playwright() as p:
        start_time = time.time()
        browser = await p.chromium.launch(
            headless=config_parser.HEADLESS,
            args=[
                "--no-sandbox",
                "--disable-setuid-sandbox",
                "--disable-gpu",
                "--disable-dev-shm-usage=true", 
            ]
        )

        semaphore = asyncio.Semaphore(config_parser.CONCURRENT_TASKS)
        flat_ids = set()

        date_str = start_time_dt.strftime("%Y-%m-%d")

        final_local = f"data/flats_{date_str}.jsonl"
        temp_local = f"data/flats_{date_str}_temp.jsonl"

        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º
        if os.path.exists(temp_local):
            os.remove(temp_local)

        async def sem_task(url):
            async with semaphore:
                # –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç–∞—Ä—Ç–∞–º–∏ –ø–æ—Ç–æ–∫–æ–≤
                await asyncio.sleep(random.uniform(1, 4)) 
                return await collect_flats_from_url(
                    browser,
                    flat_ids, 
                    url,
                    temp_local
                )

        tasks = [sem_task(u) for u in config_parser.URLS]
        await asyncio.gather(*tasks, return_exceptions=True)

        await browser.close()
        logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –°–ø–∞—Ä—Å–µ–Ω–æ {len(flat_ids)} –∫–≤–∞—Ä—Ç–∏—Ä –∑–∞ {round(time.time() - start_time)} —Å–µ–∫.")

        if os.path.exists(temp_local):
            os.replace(temp_local, final_local)
            
            year = start_time_dt.strftime("%Y")
            month = start_time_dt.strftime("%m")
            day = start_time_dt.strftime("%d")
            
            s3_object_name = f"cian/year={year}/month={month}/day={day}/flats.jsonl"
            
            if upload_file_to_s3(final_local, s3_object_name):
                logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ S3: {s3_object_name}")
                if os.path.exists(final_local):
                    os.remove(final_local) 
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –≤ S3. –§–∞–π–ª –æ—Å—Ç–∞–≤–ª–µ–Ω –ª–æ–∫–∞–ª—å–Ω–æ: {final_local}")

if __name__ == "__main__":
    asyncio.run(main())